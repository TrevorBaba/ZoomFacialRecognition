{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 : Appling ML to Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageChops, ImageFilter\n",
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "import shutil\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC \n",
    "import face_recognition\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's start with a recap of building a recognition pipeline using the face_recognition library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Classifier\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1) Create a directory called known_people (in your working directory)\n",
    "\n",
    "    a) Fill the directory with pictures of people you want the facial recognition system to be trained with\n",
    "    \n",
    "    b) Name the files (Firstname Lastname.jpg)\n",
    " \n",
    "2) Create a directory called unknown_people (in your working directory)\n",
    "\n",
    "    a) Fill the directory with pictures of people you want the facial recognition system to identify\n",
    "    \n",
    "    b) Name the files (*any name of choice*.jpg)\n",
    "    \n",
    "3) On your terminal type the following:\n",
    "    \n",
    "    face_recognition known_people unknown_people\n",
    "    \n",
    "    We can know get a comma separated output of the faces the system recognized in our unknown_people folder !\n",
    "    \n",
    "    \n",
    "**Go back to Week 2 Documentation for more Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_people/Obama Trump.png,unknown_person\n",
      "unknown_people/Obama Trump.png,Barack Obama\n",
      "unknown_people/Obama Biden.jpg,Barack Obama\n",
      "unknown_people/Obama Biden.jpg,Joe Biden\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "face_recognition known_dir unknown_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded Library Classification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/ethanchen/opt/anaconda3/lib/python3.7/site-packages (4.4.0.44)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ethanchen/opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.19.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new module to help with face-rec\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading known faces\n",
      "Joe Biden.jpg\n",
      "Barack Obama.jpg\n",
      "processing unknown faces\n",
      "Filename Obama Trump.jpg, found 2 face(s)\n",
      " - Obama from [False, True]\n",
      "Filename Obama Biden.jpg, found 2 face(s)\n",
      " - Obama from [False, True]\n",
      " - Biden from [True, False]\n"
     ]
    }
   ],
   "source": [
    "KNOWN_FACES_DIR = 'known_people'\n",
    "UNKNOWN_FACES_DIR = 'unknown_people'\n",
    "TOLERANCE = 0.6\n",
    "MODEL = 'cnn'\n",
    "print('loading known faces')\n",
    "\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "    if name == '.DS_Store':\n",
    "        pass\n",
    "        os.remove(KNOWN_FACES_DIR + '/' '.DS_Store')\n",
    "\n",
    "    # Next we load every file of faces of known person\n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "        print(filename)\n",
    "        if filename == '.DS_Store':\n",
    "            os.remove(KNOWN_FACES_DIR + '/' + name + '/'+ '.DS_Store')\n",
    "\n",
    "        # Load an image\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "\n",
    "        # Get 128-dimension face encoding\n",
    "        # Always returns a list of found faces, for this purpose we take first face only (assuming one face per image as you can't be twice on one image)\n",
    "        encoding = face_recognition.face_encodings(image)[0]\n",
    "\n",
    "        # Append encodings and name\n",
    "        known_faces.append(encoding)\n",
    "        known_names.append(name)\n",
    "\n",
    "print('processing unknown faces')\n",
    "\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    if filename == '.DS_Store':\n",
    "        os.remove(UNKNOWN_FACES_DIR + '/' '.DS_Store')\n",
    "\n",
    "    # Load image\n",
    "    print(f'Filename {filename}', end='')\n",
    "    image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}')\n",
    "\n",
    "    # This time we first grab face locations - we'll need them to draw boxes\n",
    "    locations = face_recognition.face_locations(image, model=MODEL)\n",
    "\n",
    "    # Now since we know loctions, we can pass them to face_encodings as second argument\n",
    "    # Without that it will search for faces once again slowing down whole process\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "\n",
    "    # We passed our image through face_locations and face_encodings, so we can modify it\n",
    "    # First we need to convert it from RGB to BGR as we are going to work with cv2\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # But this time we assume that there might be more faces in an image - we can find faces of dirrerent people\n",
    "    print(f', found {len(encodings)} face(s)')\n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "\n",
    "        # We use compare_faces (but might use face_distance as well)\n",
    "        # Returns array of True/False values in order of passed known_faces\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:  # If at least one is true, get a name of first of found labels\n",
    "            match = known_names[results.index(True)]\n",
    "            print(f' - {match} from {results}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Attendance Pipeline for General Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the comment \" ##### Change to Model of Choice \" in order to implement this pipeline with a different model. The default one provided here is a support vector machine. \n",
    "\n",
    "Apply the .fit and .predict principles from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Change to Model of Choice\n",
    "clf = SVC(gamma='scale')\n",
    "\n",
    "\n",
    "##### Change to Model of Choice\n",
    "def face_recognize(dir, test, pred):\n",
    "    encodings = []\n",
    "    names = []\n",
    "    attendance = set()\n",
    "    \n",
    "    #prediction - after the model has been trained \n",
    "    if pred == 1:\n",
    "        test_image = face_recognition.load_image_file(test)\n",
    "\n",
    "        # Find all the faces in the test image using the default HOG-based model\n",
    "        face_locations = face_recognition.face_locations(test_image)\n",
    "        no = len(face_locations)\n",
    "\n",
    "        # Predict all the faces in the test image using the trained classifier\n",
    "        for i in range(no):\n",
    "            test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "            \n",
    "            ##### Change to Model of Choice\n",
    "            name = clf.predict([test_image_enc])\n",
    "            \n",
    "            if name == 'unknown-male' or name == 'unknown-female':\n",
    "                location = face_locations[i]\n",
    "                tup = (location, *name)\n",
    "                attendance.add(tup)\n",
    "            \n",
    "            ##### Change to Model of Choice\n",
    "            else: \n",
    "                attendance.add(*name)\n",
    "            \n",
    "        return attendance\n",
    "\n",
    "\n",
    "    # Training the SVC classifier\n",
    "    # The training data would be all the\n",
    "    # face encodings from all the known\n",
    "    # images and the labels are their names\n",
    "\n",
    "\n",
    "    # Training directory\n",
    "    if dir[-1]!='/':\n",
    "        dir += '/'\n",
    "    train_dir = os.listdir(dir)\n",
    "\n",
    "    # Loop through each person in the training directory\n",
    "    for person in train_dir:\n",
    "        if 'DS_Store' in person:\n",
    "            continue\n",
    "        pix = os.listdir(dir + person)\n",
    "\n",
    "        # Loop through each training image for the current person\n",
    "        for person_img in pix:\n",
    "            if 'DS_Store' in person_img:\n",
    "                continue\n",
    "            # Get the face encodings for the face in each image file\n",
    "            face = face_recognition.load_image_file(\n",
    "                dir + person + \"/\" + person_img)\n",
    "            face_bounding_boxes = face_recognition.face_locations(face)\n",
    "\n",
    "            # If training image contains exactly one face\n",
    "            if len(face_bounding_boxes) == 1:\n",
    "                face_enc = face_recognition.face_encodings(face)[0]\n",
    "                # Add face encoding for current image\n",
    "                # with corresponding label (name) to the training data\n",
    "                encodings.append(face_enc)\n",
    "                names.append(person)\n",
    "            else:\n",
    "                print(person + \"/\" + person_img + \" can't be used for training\")\n",
    "\n",
    "    # Create and train the SVC classifier\n",
    "    \n",
    "    ##### Change to Model of Choice\n",
    "\n",
    "    clf.fit(encodings, names)\n",
    "    print(clf.score(encodings, names))\n",
    "    \n",
    "    ##### Change to Model of Choice\n",
    "\n",
    "    # Load the test image (passed in the method signature) with unknown faces into a numpy array\n",
    "\n",
    "    test_image = face_recognition.load_image_file(test)\n",
    "\n",
    "    # Find all the faces in the test image using the default HOG-based model\n",
    "    face_locations = face_recognition.face_locations(test_image)\n",
    "    num_face_locations = len(face_locations)\n",
    "    \n",
    "    # Predict all the faces in the test image using the trained classifier\n",
    "    for i in range(num_face_locations):\n",
    "        test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "        \n",
    "        ##### Change to Model of Choice STARTS\n",
    "        name = clf.predict([test_image_enc])\n",
    "        if name == 'unknown-male' or name == 'unknown-female':\n",
    "            location = face_locations[i]\n",
    "            tup = (location, *name)\n",
    "            attendance.add(tup)\n",
    "        \n",
    "        ##### Change to Model of Choice ENDS\n",
    "        \n",
    "        else: \n",
    "            attendance.add(*name)\n",
    "    return attendance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "attendance_set_1 = face_recognize('train_dir', 'test_3.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hammond', 'May'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_set_2 = face_recognize('train_dir', 'test_4.jpg', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Clarkson', 'Hammond', 'May'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_set_3 = face_recognize('train_dir', 'newtopgear.jpg', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((168, 1357, 297, 1228), 'unknown-male'),\n",
       " ((211, 311, 340, 182), 'unknown-male'),\n",
       " ((225, 999, 354, 870), 'unknown-male'),\n",
       " ((247, 665, 355, 557), 'unknown-female'),\n",
       " ((270, 2059, 425, 1904), 'unknown-male'),\n",
       " ((282, 1715, 411, 1586), 'unknown-male')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_set_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unknowns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0da035a68ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munknowns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattendance_set_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'newtopgear.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'unknowns' is not defined"
     ]
    }
   ],
   "source": [
    "unknowns(attendance_set_3, 'newtopgear.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Zoom Bombers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "tup = (1,2)\n",
    "if type(tup) == tuple:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknowns(attendance_set, test_image):\n",
    "    if 'Unknowns' not in os.listdir():\n",
    "        os.mkdir('Unknowns')\n",
    "    i = 0\n",
    "    for item in attendance_set:\n",
    "        if type(item) == tuple:\n",
    "            item = item[0]\n",
    "            \n",
    "        if type(item) != np.str_ :\n",
    "            image = face_recognition.load_image_file(test_image)\n",
    "            top, right, bottom, left = item\n",
    "            faceImage = image[top:bottom, left:right]\n",
    "            final = Image.fromarray(faceImage)\n",
    "            final.save('Unknowns/unknown_' + str(i) + '.jpg')\n",
    "            i = i + 1\n",
    "    if len(os.listdir('Unknowns')) == 0:\n",
    "        print('No Unknown Faces')\n",
    "        return\n",
    "        \n",
    "    for file in os.listdir('Unknowns'):\n",
    "        if file != '.DS_Store':\n",
    "            image = Image.open('Unknowns/' + file)\n",
    "            image.show()\n",
    "            classification = input('Type of Person: ')\n",
    "            if classification == 'Unknown Male':\n",
    "                shutil.move('Unknowns/' + file, 'train_dir/unknown-male/' + file)\n",
    "            elif classification == 'Unknown Female':\n",
    "                shutil.move('Unknowns/' +file, 'train_dir/unknown-female/' + file)\n",
    "            else:\n",
    "                shutil.move('Unknowns/' +file, 'train_dir/' + classification + '/' + file)\n",
    "    print('Unknown Faces Accounted')\n",
    "    return\n",
    "    \n",
    "            \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
